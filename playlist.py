import streamlit as st
import pandas as pd
import nltk
from transformers import pipeline, AutoTokenizer
from sklearn.feature_extraction.text import TfidfVectorizer
import plotly.express as px
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import os
from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import spacy
from math import pi
import numpy as np 
# ë°ì´í„° ë¡œë“œë¥¼ ìºì‹œ ì²˜ë¦¬

# í•„ìš”í•  ìˆ˜ ìˆëŠ” ë‹¤ë¥¸ NLTK ë°ì´í„°ë„ ì„¤ì¹˜
required_nltk_packages = ['punkt', 'averaged_perceptron_tagger', 'wordnet']
for package in required_nltk_packages:
    try:
        nltk.data.find(package)
    except LookupError:
        nltk.download(package)
def app():
    @st.cache_data
    def load_data():
        df = pd.read_csv('1jo/all_songs_data.csv')
        # punkt ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ ì‹œë„
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            nltk.download('punkt')
        # ë¶ˆìš©ì–´ í™•ì¥í•˜ê¸°
        stop_words = set(stopwords.words('english'))  # ê¸°ë³¸ ì˜ì–´ ë¶ˆìš©ì–´ ëª©ë¡ ë¡œë“œ
        stop_words_spacy = set(spacy.load('en_core_web_sm').Defaults.stop_words)
        stop_words_sklearn = set(ENGLISH_STOP_WORDS)
        additional_stopwords = [
            'verse', 'chorus', 'i"ll', 'intro', 'outro', 'or', 'm', 'ma', 'ours', 'against', 'nor',
            'wasn', 'hasn', 'my', 'had', 'didn', 'isn', 'did', 'aren', 'those', 'than', 'man',
            "mustn't", "you've", 'to', 'she', 'having', "haven't", 'into', 't', 'll', 's','n',
            'himself', 'do', "that'll", 'so', 'of', 'on', 'very', 'for', 'out', 'were', '\'',
            'should', 'they', 'ain', "should've", 'you', "didn't", 'yours', 'was', 'our','ll',
            'can', 'myself', "shouldn't", 'have', 'up', 'mightn', "you'll", 'any', 't',
            'itself', 'hadn', 'him', 'doesn', 'weren', 'y', 'being', "don't", 'them', 
            'are', 'and', 'that', 'your', 'yourself', 'their', 'some', 'ourselves', 've', 
            'doing', 'been', 'shouldn', 'yourselves', "mightn't", 'most', 'because',
            'few', 'wouldn', "you'd", 'through', "you're", 'themselves', 'an', 'if',
            "wouldn't", 'its', 'other', "won't", "wasn't", "she's", 'we', 'shan',
            "weren't", 'don', "hadn't", 'this', 'off', 'while', 'a', 'haven', 'her', 
            'theirs', 'all', "hasn't", "doesn't", 'about', 'then', 'by', 'such', 'but', 
            'until', 'each', 'there', "aren't", 'with', 'not', "shan't", 'hers', 'it', 
            'too', 'i', 'at', 'is', 'as', 'me', 'herself', 's', 'the', 'where', 'am', 
            'has', 'over', "couldn't", 'when', 'does', 'mustn', 're', 'no', 'in', 'who', 
            'd', 'own', 'he', 'be', "isn't", 'his', 'these', 'same', 'whom', 'will', 
            'needn', 'couldn', 'from', "it's", 'o', 'yeah', 'ya', 'na', 'wan', 'uh', 'gon',
            'ima', 'mm', 'uhhuh', 'bout', 'em', 'nigga', 'niggas', 'got', 'ta', 'lil', 'ol', 'hey',
            'oooh', 'ooh', 'oh', 'youre', 'dont', 'im', 'youve', 'ive', 'theres', 'ill', 'yaka',
            'lalalala', 'la', 'da', 'di', 'yuh', 'shawty', 'oohooh', 'shoorah', 'mmmmmm',
            'ook', 'bidibambambambam', 'shh', 'bro', 'ho', 'aint', 'cant', 'know', 'bambam',
            'shitll', 'tonka','fn','ai'
        ]
    
        # ìµœì¢… ë¶ˆìš©ì–´ í†µí•©
        stop_words = stop_words.union(stop_words_spacy).union(stop_words_sklearn).union(set(additional_stopwords))
    
        # ê°€ì‚¬ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜)
        def preprocess_lyrics(text):
            if isinstance(text, str):
                text = text.lower()
                words = word_tokenize(text)
                words = [word for word in words if word.isalpha() and word not in stop_words]
                lemmatizer = WordNetLemmatizer()
                words = [lemmatizer.lemmatize(word) for word in words]
                return words  # ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
            else:
                return []
    
        # ë°ì´í„°í”„ë ˆì„ì— 'processed_lyrics' ì—´ ì¶”ê°€
        df['processed_lyrics_set'] = df['Lyrics'].apply(preprocess_lyrics)
        df['lyrics_for_emotion'] = df['Lyrics']
        return df
    
    # ê°ì„± ë¶„ì„ ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ (í—ˆê¹…í˜ì´ìŠ¤)
    @st.cache_resource
    def load_sentiment_model():
        sentiment_analyzer = pipeline('text-classification', model='bhadresh-savani/bert-base-uncased-emotion', device=0)
        tokenizer = AutoTokenizer.from_pretrained('bhadresh-savani/bert-base-uncased-emotion')
        return sentiment_analyzer, tokenizer
    
    # ë°ì´í„° ë¡œë“œ
    df = load_data()
    sentiment_analyzer, tokenizer = load_sentiment_model()
    def plot_radar_chart(df):
        # ë ˆì´ë” ì°¨íŠ¸ ì„¤ì •
        categories = list(df.keys())
        values = list(df.values())
        
        N = len(categories)
        
        # ë ˆì´ë” ì°¨íŠ¸ë¥¼ ìœ„í•œ ê°ë„ ê³„ì‚°
        angles = [n / float(N) * 2 * pi for n in range(N)]
        angles += angles[:1]  # ë ˆì´ë” ì°¨íŠ¸ë¥¼ ë‹«ê¸° ìœ„í•´ ì²« ë²ˆì§¸ ê°ë„ë¥¼ ë§ˆì§€ë§‰ì—ë„ ì¶”ê°€
        
        values += values[:1]  # ë ˆì´ë” ì°¨íŠ¸ë¥¼ ë‹«ê¸° ìœ„í•´ ì²« ë²ˆì§¸ ê°’ì„ ë§ˆì§€ë§‰ì—ë„ ì¶”ê°€
    
        # ë ˆì´ë” ì°¨íŠ¸ ê·¸ë¦¬ê¸°
        plt.figure(figsize=(8, 8))
        ax = plt.subplot(111, polar=True)
        # ì°¨íŠ¸ì˜ ë°°ê²½, ê·¸ë¦¬ë“œ ë° í‹± ì„¤ì •
        ax.set_facecolor('white')  # ë°°ê²½ìƒ‰
        plt.xticks(angles[:-1], categories, color='darkblue', size=12)  # ì¹´í…Œê³ ë¦¬ ë¼ë²¨ ì„¤ì •
        ax.yaxis.grid(True, color='grey', linestyle='--', linewidth=0.5)  # ê·¸ë¦¬ë“œ ë¼ì¸ ìŠ¤íƒ€ì¼
        ax.xaxis.grid(True, color='grey', linestyle='--', linewidth=0.5)
        plt.xticks(angles[:-1], categories)
        
        ax.plot(angles, values)
        ax.fill(angles, values, 'b', alpha=0.1)
        # ë ˆì´ë” ì°¨íŠ¸ ì„  ê·¸ë¦¬ê¸°
        ax.plot(angles, values, linewidth=2, linestyle='solid', color='blue')
        ax.fill(angles, values, 'blue', alpha=0.3)  # ë‚´ë¶€ ì±„ìš°ê¸° ìƒ‰ìƒê³¼ íˆ¬ëª…ë„ ì„¤ì •
        # ìµœëŒ€ê°’ì„ êµ¬í•˜ê³  ìµœëŒ€ê°’ë³´ë‹¤ 0.1 í¬ê²Œ ì„¤ì •
        max_value = max(values)
        plt.ylim(0, max_value + 0.1)
    
        # ë™ì ìœ¼ë¡œ yticks ì„¤ì •
        yticks = np.linspace(0, max_value + 0.1, num=6)  # ìµœëŒ€ê°’ì— ë”°ë¼ ë™ì ìœ¼ë¡œ yticks ìƒì„±
        plt.yticks(yticks, color="grey", size=10)
    
            # ì¤‘ì•™ ì› ìŠ¤íƒ€ì¼ë§
        ax.spines['polar'].set_color('darkblue')
        ax.spines['polar'].set_linewidth(1)
    
        st.pyplot(plt)
    
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì œëª©
    st.title('My Custom Playlist Builder ğŸµ')
    
    # ì´ˆê¸° ê²€ìƒ‰ì–´ì™€ ê²€ìƒ‰ ì˜µì…˜ ì„¤ì •
    search_lyrics = st.text_input("Enter lyrics or title to search for songs:", value="Christmas")
    search_option = st.radio("Search in:", ( 'Title','Lyrics'))
    
    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
    if 'playlist' not in st.session_state:
        st.session_state.playlist = []
    
    # ì„ íƒëœ ë…¸ë˜ë¥¼ ì €ì¥í•  ìƒíƒœ ì´ˆê¸°í™”
    if 'selected_songs' not in st.session_state:
        st.session_state['selected_songs'] = []
    
    # ë¹ˆ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì´ˆê¸°í™”
    filtered_songs = pd.DataFrame()
    
    # ê°€ì‚¬ë‚˜ ì œëª©ìœ¼ë¡œ ë…¸ë˜ ê²€ìƒ‰
    if search_lyrics:
        if search_option == 'Lyrics':
            filtered_songs = df[df['Lyrics'].str.contains(search_lyrics, case=False, na=False)]
        elif search_option == 'Title':
            filtered_songs = df[df['Song Title'].str.contains(search_lyrics, case=False, na=False)]
    
    # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
    st.subheader("Search Results")
    show_lyrics = st.checkbox("ë…¸ë˜ì™€ ê°€ì‚¬ ë³´ê¸°")
    if not filtered_songs.empty and show_lyrics:
        button_out = "ë…¸ë˜ì™€ ê°€ì‚¬ ë¦¬ìŠ¤íŠ¸"
        
        for index, row in filtered_songs.iterrows():
            button_label = f"{row['Song Title']} by {row['Artist']} ({int(row['Year'])}) - Rank: {row['Rank']}"
            with st.expander(button_label):
                st.text_area(
                    f"Lyrics of {row['Song Title']} by {row['Artist']}",
                    row['Lyrics'],
                    height=200,
                    key=f"lyrics_{index}"
                )
    elif filtered_songs.empty :
        st.write("No results found. Please try a different search term.")
    else :
        st.write(" ")
    
    # ë“œë˜ê·¸ ì•¤ ë“œë¡­ ë˜ëŠ” ì„ íƒì„ í†µí•´ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    st.subheader("Build Your Playlist")
    if not filtered_songs.empty:
        unique_songs = filtered_songs[['Song Title', 'Artist']].apply(lambda x: f"{x['Song Title']} by {x['Artist']}", axis=1).unique()
        selected_songs = st.multiselect('Select songs to add to your playlist:', unique_songs, default=st.session_state.selected_songs)
        st.session_state.selected_songs = selected_songs
    else:
        selected_songs = []
    
    # **Add to Playlist** ë²„íŠ¼ì„ ì‚¬ìš©í•˜ì—¬ ì„ íƒëœ ë…¸ë˜ë¥¼ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
    if st.button('Add to Playlist'):
        for song in st.session_state.selected_songs:
            if song not in st.session_state.playlist:
                st.session_state.playlist.append(song)
        st.session_state.playlist = list(set(st.session_state.playlist))  # ì¤‘ë³µ ì œê±°
        st.success(f"Added {len(st.session_state.selected_songs)} songs to your playlist!")
        st.session_state.selected_songs.clear()
    
    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ í‘œì‹œ ë° ë…¸ë˜ ì œê±° ê¸°ëŠ¥
    playlist_container = st.container()
    with playlist_container:
        if st.session_state.playlist:
            playlist_df = pd.DataFrame(st.session_state.playlist, columns=["Song"])
            playlist_df['Remove'] = playlist_df.index
            playlist_df.set_index('Song', inplace=True)
            st.table(playlist_df)
    
            # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ë…¸ë˜ ì œê±°
            for i, song in enumerate(st.session_state.playlist):
                if st.button(f"Remove {song}", key=f"remove_{i}"):
                    st.session_state.playlist.remove(song)
    
                    # ìƒíƒœê°€ ë³€ê²½ë˜ì—ˆìŒì„ í‘œì‹œí•˜ê³ , UIë¥¼ ìƒˆë¡œ ê³ ì¹¨í•˜ë„ë¡ í•¨
                    with playlist_container:
                        st.experimental_set_query_params()  # ìƒíƒœ ë³€ê²½ í›„ í˜ì´ì§€ë¥¼ ìƒˆë¡œ ê³ ì¹¨
                        st.session_state.playlist = st.session_state.playlist  # ìƒíƒœ ì—…ë°ì´íŠ¸
                    break
    
    # ìƒíƒœê°€ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì¬ë Œë”ë§
    if 'reload' in st.session_state:
        st.session_state.pop('reload', None)  # ìƒíƒœ ì œê±°í•˜ì—¬ ë¬´í•œ ë£¨í”„ ë°©ì§€
    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ë¶„ì„
    if st.session_state.playlist:
        with st.container():  # ë¶„ì„ ê²°ê³¼ì™€ ì›Œë“œ 
            st.subheader("Playlist Analysis")
            
            # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì˜ ê°€ì‚¬ ê°€ì ¸ì˜¤ê¸°
            playlist_lyrics = df[df['Song Title'].isin([s.split(' by ')[0] for s in st.session_state.playlist])]['processed_lyrics_set'].sum()
            
            # í‚¤ì›Œë“œ ì¶”ì¶œ (TF-IDF)
            st.markdown("### Playlist Keywords")
            tfidf_vectorizer = TfidfVectorizer(max_features=10)
            tfidf_matrix = tfidf_vectorizer.fit_transform([' '.join(playlist_lyrics)])
            feature_names = tfidf_vectorizer.get_feature_names_out()
            scores = tfidf_matrix.toarray().flatten()
            tfidf_scores = pd.DataFrame({'Term': feature_names, 'Score': scores})
            tfidf_scores = tfidf_scores.sort_values(by='Score', ascending=False)
    
            # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„±
            wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(tfidf_scores.set_index('Term').to_dict()['Score'])
            plt.figure(figsize=(10, 5))
            plt.imshow(wordcloud, interpolation='bilinear')
            plt.axis('off')
            st.pyplot(plt)
    
            # ê°ì„± ë¶„ì„
            st.markdown("### Sentiment Analysis")
    
            # ê°ì„± ë¶„ì„ì— ì‚¬ìš©í•  í…ìŠ¤íŠ¸ë¥¼ ìµœëŒ€ ê¸¸ì´ë¡œ ìë¥´ê¸° (ëª¨ë¸ ì…ë ¥ í¬ê¸° ì œí•œ)
            max_length = 512
    
            # ê° ê³¡ë³„ë¡œ ê°ì„± ì ìˆ˜ë¥¼ ê³„ì‚°
            sentiment_scores_list = []
    
            for lyric in playlist_lyrics:
                inputs = tokenizer(lyric, return_tensors='pt', truncation=True, max_length=max_length)
                truncated_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)
                
                # ê°ì„± ë¶„ì„ (ì†ë„ ê°œì„ ì„ ìœ„í•´ batch_size ì‚¬ìš©)
                sentiments = sentiment_analyzer(truncated_text, batch_size=8)
                song_sentiment_scores = {label: 0 for label in ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}
                
                for sentiment in sentiments:
                    song_sentiment_scores[sentiment['label']] += sentiment['score']
    
                sentiment_scores_list.append(song_sentiment_scores)
    
            # ê³¡ë³„ ê°ì„± ì ìˆ˜ë¥¼ í‰ê· í•˜ì—¬ ì „ì²´ ê°ì„± ì ìˆ˜ë¥¼ ê³„ì‚°
            avg_sentiment_scores = {label: 0 for label in ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']}
            
            for scores in sentiment_scores_list:
                for label, score in scores.items():
                    avg_sentiment_scores[label] += score
            avg_sentiment_scores['anger'] *= (2 / 3)
            
              # í‰ê·  ì ìˆ˜ ê³„ì‚°
            avg_sentiment_scores = {label: score / len(sentiment_scores_list) for label, score in avg_sentiment_scores.items()}
    
            labels = list(avg_sentiment_scores.keys())
            values = list(avg_sentiment_scores.values())
    
            # ê°ì • ë¶„ì„ ê²°ê³¼ì—ì„œ ê°€ì¥ ë†’ì€ ê°ì •ì„ ì°¾ê¸°
            dominant_emotion = max(avg_sentiment_scores, key=avg_sentiment_scores.get)
            st.write(f"Your playlist's predominant emotion is **{dominant_emotion.capitalize()}**!")
            st.table(avg_sentiment_scores)
            plot_radar_chart(avg_sentiment_scores)
            #plot_radar_chart(avg_sentiment_scores)
            # ê°ì •ì— ë”°ë¥¸ ì´ë¯¸ì§€ í‘œì‹œ
            emotion_images = {
                'sadness': '1jo/sadness.svg',
                'joy': '1jo/joy.svg',
                'love': '1jo/love.svg',
                'anger': '1jo/anger.svg',
                'fear': '1jo/fear.svg',
                'surprise': '1jo/surprise.svg'
            }
    
            if dominant_emotion in emotion_images:
                st.image(emotion_images[dominant_emotion], caption=f"Emotion: {dominant_emotion.capitalize()}", use_column_width=True)